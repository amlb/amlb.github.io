# 10 octobre 2018
- Animateur: Paul Nguyen Hong Duc
- Question concrète: Approche classique image pour traiter le son, consistant à apprendre des features sur des MFCCs (mel frequency cepstrum coefficients), améliore-t-elle la reconnaissance automatique de scènes acoustiques?
- Méthode machine learning: CNN 1 couche
- Dataset formatté et benchmarké: DCLDE 2018 LF (website does not work [sabiod.univ-tln.fr/DCLDE](sabiod.univ-tln.fr/DCLDE))

## Notebooks et fichiers data:
- [AtelierML.ipynb](https://github.com/amlb/amlb.github.io/blob/master/2018-10-10_CNN_Whales/AtelierML.ipynb): jupyter notebook python de l'atelier
- [allWavSamples](https://github.com/amlb/amlb.github.io/blob/master/2018-10-10_CNN_Whales/allWavSamples): dossier des fichiers .wav utilisés dans le notebook
